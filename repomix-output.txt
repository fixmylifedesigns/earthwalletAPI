This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-07-09T01:44:37.319Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
.gitignore
app.py
auth/firebase.py
config.py
docker-compose.yml
Dockerfile
extensions.py
migrations/alembic.ini
migrations/env.py
migrations/README
migrations/script.py.mako
migrations/versions/4c80ce72f155_initial_schema.py
models/__init__.py
README.md
requirements.txt
routes/deposit.py
routes/user.py
routes/wallet.py
routes/withdraw.py

================================================================
Repository Files
================================================================

================
File: .gitignore
================
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[codz]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py.cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock
#poetry.toml

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#   pdm recommends including project-wide configuration in pdm.toml, but excluding .pdm-python.
#   https://pdm-project.org/en/latest/usage/project/#working-with-version-control
#pdm.lock
#pdm.toml
.pdm-python
.pdm-build/

# pixi
#   Similar to Pipfile.lock, it is generally recommended to include pixi.lock in version control.
#pixi.lock
#   Pixi creates a virtual environment in the .pixi directory, just like venv module creates one
#   in the .venv directory. It is recommended not to include this directory in version control.
.pixi

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.envrc
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

# Abstra
# Abstra is an AI-powered process automation framework.
# Ignore directories containing user credentials, local state, and settings.
# Learn more at https://abstra.io/docs
.abstra/

# Visual Studio Code
#  Visual Studio Code specific template is maintained in a separate VisualStudioCode.gitignore 
#  that can be found at https://github.com/github/gitignore/blob/main/Global/VisualStudioCode.gitignore
#  and can be added to the global gitignore or merged into this file. However, if you prefer, 
#  you could uncomment the following to ignore the entire vscode folder
# .vscode/

# Ruff stuff:
.ruff_cache/

# PyPI configuration file
.pypirc

# Cursor
#  Cursor is an AI-powered code editor. `.cursorignore` specifies files/directories to
#  exclude from AI features like autocomplete and code analysis. Recommended for sensitive data
#  refer to https://docs.cursor.com/context/ignore-files
.cursorignore
.cursorindexingignore

# Marimo
marimo/_static/
marimo/_lsp/
__marimo__/

================
File: app.py
================
from flask import Flask
from flask_cors import CORS
from extensions import db, limiter, migrate
from routes.wallet import wallet_bp
from routes.user import user_bp
from routes.deposit import deposit_bp
from routes.withdraw import withdraw_bp
from config import Config
import os
import logging
import firebase_admin
from firebase_admin import credentials

def create_app():
    app = Flask(__name__)
    CORS(app)
    app.config.from_object(Config)
    
    # Configure logging for both development and production
    logging.basicConfig(level=logging.INFO)
    app.logger.setLevel(logging.INFO)
    
    # Initialize Firebase
    if not firebase_admin._apps:
        firebase_creds = app.config.get("FIREBASE_SERVICE_ACCOUNT")
        if firebase_creds:
            try:
                cred = credentials.Certificate(firebase_creds)
                firebase_admin.initialize_app(cred)
                app.logger.info("Firebase initialized successfully")
            except Exception as e:
                app.logger.error(f"Failed to initialize Firebase: {e}")
        else:
            app.logger.warning("FIREBASE_SERVICE_ACCOUNT not found. Firebase will not be initialized.")
    
    # Log configuration on startup
    app.logger.info(f"Flask Environment: {app.config.get('FLASK_ENV', 'production')}")
    app.logger.info(f"Firebase Project ID: {app.config.get('FIREBASE_PROJECT_ID')}")
    app.logger.info(f"TEST_USER_EMAIL: {os.getenv('TEST_USER_EMAIL')}")
    app.logger.info(f"Database URL configured: {bool(app.config.get('SQLALCHEMY_DATABASE_URI'))}")
    app.logger.info(f"Stripe Key configured: {bool(os.getenv('STRIPE_SECRET_KEY'))}")
    
    # Initialize extensions
    db.init_app(app)
    limiter.init_app(app)
    migrate.init_app(app, db)
    
    # Handle database setup more gracefully
    with app.app_context():
        try:
            # Import models to ensure they're registered
            from models import User, Wallet, Transaction, Withdrawal
            
            # Test database connection first
            db.session.execute('SELECT 1')
            app.logger.info("Database connection successful")
            
            # Try to create tables if they don't exist
            try:
                db.create_all()
                app.logger.info("Database tables verified/created")
            except Exception as table_error:
                app.logger.warning(f"Table creation issue (likely tables already exist): {table_error}")
                # Tables probably already exist, continue anyway
            
        except Exception as e:
            app.logger.error(f"Database setup error: {e}")
            # Don't crash the app, just log the error
    
    # Register blueprints
    app.register_blueprint(user_bp)
    app.register_blueprint(wallet_bp)
    app.register_blueprint(deposit_bp)
    app.register_blueprint(withdraw_bp)
    
    @app.route('/health')
    def health_check():
        """Health check endpoint"""
        try:
            # Test database connection
            db.session.execute('SELECT 1')
            db_status = "connected"
        except Exception as e:
            db_status = f"error: {str(e)}"
        
        return {
            'status': 'healthy',
            'database': db_status,
            'firebase': bool(firebase_admin._apps),
            'environment': app.config.get('FLASK_ENV', 'production')
        }, 200
    
    @app.route('/debug/config')
    def debug_config():
        """Debug endpoint to check configuration"""
        return {
            'firebase_project_id': app.config.get('FIREBASE_PROJECT_ID'),
            'test_user_email': os.getenv('TEST_USER_EMAIL'),
            'has_database_url': bool(app.config.get('SQLALCHEMY_DATABASE_URI')),
            'has_stripe_key': bool(os.getenv('STRIPE_SECRET_KEY')),
            'environment': app.config.get('FLASK_ENV', 'production'),
            'firebase_initialized': bool(firebase_admin._apps)
        }, 200
    
    @app.route('/')
    def index():
        """Root endpoint"""
        return {
            'message': 'RecycleTek Wallet API',
            'version': '1.0.0',
            'status': 'running',
            'endpoints': {
                'health': '/health',
                'debug': '/debug/config',
                'wallet': '/wallet',
                'deposit': '/deposit',
                'withdraw': '/withdraw',
                'validate_kiosk': '/validate-kiosk-id'
            }
        }, 200
    
    app.logger.info("Flask app created successfully")
    return app

# Create app instance for gunicorn
app = create_app()

# Create the app instance for gunicorn
app = create_app()

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    app.run(host="0.0.0.0", port=port, debug=False)

================
File: auth/firebase.py
================
# auth/firebase.py
from functools import wraps
from flask import request, jsonify, current_app, g
import firebase_admin
from firebase_admin import credentials, auth
from models import User
from extensions import db
import json, os, secrets, string

# ───────────────────────── Firebase bootstrap ─────────────────────────
try:
    firebase_admin.get_app()
except ValueError:                       # first run
    service_account_info = json.loads(os.environ["FIREBASE_SERVICE_ACCOUNT"])
    cred = credentials.Certificate(service_account_info)
    firebase_admin.initialize_app(cred)

# ────────────────────────── helpers ───────────────────────────────────
def generate_kiosk_id() -> str:
    """Generate a unique 8-character alphanumeric kiosk ID."""
    while True:
        kiosk_id = "".join(secrets.choice(string.ascii_uppercase + string.digits) for _ in range(8))
        if not User.query.filter_by(kiosk_id=kiosk_id).first():
            return kiosk_id

# ────────────────────────── main decorator ────────────────────────────
def firebase_required(view):
    """Accept   ① dev bypass   ② kiosk-ID   ③ Firebase Bearer token."""
    @wraps(view)
    def wrapped(*args, **kwargs):
        current_app.logger.info("=== Auth Debug ===")
        current_app.logger.info(f"{request.method} {request.url}")
        current_app.logger.info(f"Headers: {dict(request.headers)}")

        # ---------- 1) dev bypass ------------------------------------------------
        test_hdr   = request.headers.get("X-Test-User-Email")
        test_email = os.getenv("TEST_USER_EMAIL")
        if test_hdr and test_email and test_hdr == test_email:
            user = User.query.filter_by(email=test_hdr).first()
            if not user:
                user = User(
                    firebase_uid=f"test-{test_hdr}",
                    email=test_hdr,
                    kiosk_id=generate_kiosk_id(),
                )
                db.session.add(user)
                db.session.commit()
            else:
                if not user.kiosk_id:
                    user.kiosk_id = generate_kiosk_id()
                    db.session.commit()
            g.current_user = user
            return view(user, *args, **kwargs)

        # ---------- 2) kiosk-ID --------------------------------------------------
        raw_json = request.get_json(silent=True)  # never raises
        kiosk_id = request.headers.get("X-Kiosk-User-ID") or (raw_json or {}).get("kiosk_id")
        if kiosk_id:
            user = User.query.filter_by(kiosk_id=kiosk_id.upper()).first()
            if not user:
                return jsonify(error="Invalid kiosk ID"), 401
            g.current_user = user
            return view(user, *args, **kwargs)

        # ---------- 3) Firebase Bearer token ------------------------------------
        auth_header = request.headers.get("Authorization", "")
        if not auth_header.startswith("Bearer "):
            return jsonify(
                error="Authorization required. Use Bearer token, "
                      "X-Kiosk-User-ID header, or kiosk_id in body"
            ), 401

        id_token = auth_header.split(" ", 1)[1]
        try:
            decoded = auth.verify_id_token(id_token)
        except Exception as e:  # noqa: BLE001
            current_app.logger.warning(f"Token verify failed: {e}")
            return jsonify(error="Invalid or expired token"), 401

        uid   = decoded["uid"]
        email = decoded.get("email")
        if not email:
            return jsonify(error="Email claim missing"), 401

        user = User.query.filter_by(firebase_uid=uid).first()
        if not user:
            user = User(firebase_uid=uid, email=email, kiosk_id=generate_kiosk_id())
            db.session.add(user)
            db.session.commit()
        else:
            if not user.kiosk_id:
                user.kiosk_id = generate_kiosk_id()
                db.session.commit()

        g.current_user = user
        return view(user, *args, **kwargs)

    return wrapped

# ───────────────────── kiosk-only decorator ───────────────────────────
def kiosk_only(view):
    """Endpoint accessible **only** with a kiosk ID."""
    @wraps(view)
    def wrapped(*args, **kwargs):
        raw_json = request.get_json(silent=True)
        kiosk_id = request.headers.get("X-Kiosk-User-ID") or (raw_json or {}).get("kiosk_id")
        if not kiosk_id:
            return jsonify(error="Kiosk ID required"), 401

        user = User.query.filter_by(kiosk_id=kiosk_id.upper()).first()
        if not user:
            return jsonify(error="Invalid kiosk ID"), 401

        g.current_user = user
        return view(user, *args, **kwargs)

    return wrapped

================
File: config.py
================
import os
import json
from dotenv import load_dotenv

load_dotenv()

class Config:
    SECRET_KEY = os.environ.get('SECRET_KEY') or 'dev-secret-key-change-in-production'
    SQLALCHEMY_DATABASE_URI = os.environ.get('DATABASE_URL') or 'postgresql://postgres:password@localhost/recycling_wallet'
    SQLALCHEMY_TRACK_MODIFICATIONS = False
    
    # Firebase
    FIREBASE_SERVICE_ACCOUNT = json.loads(os.getenv("FIREBASE_SERVICE_ACCOUNT", "{}"))
    FIREBASE_PROJECT_ID = FIREBASE_SERVICE_ACCOUNT.get("project_id")
    
    # Stripe
    STRIPE_SECRET_KEY = os.environ.get('STRIPE_SECRET_KEY')
    
    # Redis
    REDIS_URL = os.environ.get('REDIS_URL') or 'redis://localhost:6379'
    
    # Rate limiting
    RATELIMIT_STORAGE_URL = REDIS_URL or 'memory://'
    RATELIMIT_DEFAULT = "1000 per hour"
    
    # Dev/testing
    TEST_USER_EMAIL = os.environ.get('TEST_USER_EMAIL')
    
    @staticmethod
    def init_app(app):
        app.logger.info(f"Firebase Project ID configured: {bool(Config.FIREBASE_PROJECT_ID)}")
        app.logger.info(f"Test User Email configured: {bool(Config.TEST_USER_EMAIL)}")

================
File: docker-compose.yml
================
version: '3.8'

services:
  app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/recycling_wallet
      - REDIS_URL=redis://redis:6379
      - FLASK_ENV=development
      - FIREBASE_PROJECT_ID=${FIREBASE_PROJECT_ID}
      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}
      - TEST_USER_EMAIL=test@example.com   
    depends_on:
      - db
      - redis
    volumes:
      - .:/app
      - ./serviceAccount.json:/app/serviceAccount.json:ro
    command: ["flask", "run", "--host=0.0.0.0", "--port=8000"]

  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=recycling_wallet
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

volumes:
  postgres_data:

================
File: Dockerfile
================
FROM python:3.12-slim

WORKDIR /app

RUN apt-get update && apt-get install -y \
    gcc \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

RUN adduser --disabled-password --gecos '' appuser
RUN chown -R appuser:appuser /app
USER appuser

EXPOSE 8000

CMD ["gunicorn", "app:app", "--bind", "0.0.0.0:8000", "--workers", "1", "--timeout", "120"]

================
File: extensions.py
================
from flask_sqlalchemy import SQLAlchemy
from flask_migrate import Migrate
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address

db = SQLAlchemy()
migrate = Migrate()
limiter = Limiter(
    key_func=get_remote_address,
    default_limits=["1000 per hour"]
)

================
File: migrations/alembic.ini
================
# A generic, single database configuration.

[alembic]
# template used to generate migration files
# file_template = %%(rev)s_%%(slug)s

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false


# Logging configuration
[loggers]
keys = root,sqlalchemy,alembic,flask_migrate

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[logger_flask_migrate]
level = INFO
handlers =
qualname = flask_migrate

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S

================
File: migrations/env.py
================
import logging
from logging.config import fileConfig

from flask import current_app

from alembic import context

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
fileConfig(config.config_file_name)
logger = logging.getLogger('alembic.env')


def get_engine():
    try:
        # this works with Flask-SQLAlchemy<3 and Alchemical
        return current_app.extensions['migrate'].db.get_engine()
    except (TypeError, AttributeError):
        # this works with Flask-SQLAlchemy>=3
        return current_app.extensions['migrate'].db.engine


def get_engine_url():
    try:
        return get_engine().url.render_as_string(hide_password=False).replace(
            '%', '%%')
    except AttributeError:
        return str(get_engine().url).replace('%', '%%')


# add your model's MetaData object here
# for 'autogenerate' support
# from myapp import mymodel
# target_metadata = mymodel.Base.metadata
config.set_main_option('sqlalchemy.url', get_engine_url())
target_db = current_app.extensions['migrate'].db

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


def get_metadata():
    if hasattr(target_db, 'metadatas'):
        return target_db.metadatas[None]
    return target_db.metadata


def run_migrations_offline():
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url, target_metadata=get_metadata(), literal_binds=True
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online():
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """

    # this callback is used to prevent an auto-migration from being generated
    # when there are no changes to the schema
    # reference: http://alembic.zzzcomputing.com/en/latest/cookbook.html
    def process_revision_directives(context, revision, directives):
        if getattr(config.cmd_opts, 'autogenerate', False):
            script = directives[0]
            if script.upgrade_ops.is_empty():
                directives[:] = []
                logger.info('No changes in schema detected.')

    conf_args = current_app.extensions['migrate'].configure_args
    if conf_args.get("process_revision_directives") is None:
        conf_args["process_revision_directives"] = process_revision_directives

    connectable = get_engine()

    with connectable.connect() as connection:
        context.configure(
            connection=connection,
            target_metadata=get_metadata(),
            **conf_args
        )

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()

================
File: migrations/README
================
Single-database configuration for Flask.

================
File: migrations/script.py.mako
================
"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from alembic import op
import sqlalchemy as sa
${imports if imports else ""}

# revision identifiers, used by Alembic.
revision = ${repr(up_revision)}
down_revision = ${repr(down_revision)}
branch_labels = ${repr(branch_labels)}
depends_on = ${repr(depends_on)}


def upgrade():
    ${upgrades if upgrades else "pass"}


def downgrade():
    ${downgrades if downgrades else "pass"}

================
File: migrations/versions/4c80ce72f155_initial_schema.py
================
"""initial schema

Revision ID: 4c80ce72f155
Revises: 
Create Date: 2025-07-08 21:50:44.033025

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '4c80ce72f155'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('users',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('firebase_uid', sa.String(length=128), nullable=False),
    sa.Column('email', sa.String(length=255), nullable=False),
    sa.Column('kiosk_id', sa.String(length=8), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_users_firebase_uid'), ['firebase_uid'], unique=True)
        batch_op.create_index(batch_op.f('ix_users_kiosk_id'), ['kiosk_id'], unique=True)

    op.create_table('wallets',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.Column('balance_cents', sa.Integer(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('user_id')
    )
    op.create_table('transactions',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.Column('wallet_id', sa.UUID(), nullable=False),
    sa.Column('transaction_type', sa.String(length=20), nullable=False),
    sa.Column('material', sa.String(length=50), nullable=True),
    sa.Column('units', sa.Integer(), nullable=True),
    sa.Column('amount_cents', sa.Integer(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.ForeignKeyConstraint(['wallet_id'], ['wallets.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('withdrawals',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.Column('wallet_id', sa.UUID(), nullable=False),
    sa.Column('amount_cents', sa.Integer(), nullable=False),
    sa.Column('bank_token', sa.String(length=255), nullable=False),
    sa.Column('stripe_payment_intent_id', sa.String(length=255), nullable=True),
    sa.Column('status', sa.String(length=20), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('processed_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.ForeignKeyConstraint(['wallet_id'], ['wallets.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('withdrawals')
    op.drop_table('transactions')
    op.drop_table('wallets')
    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_users_kiosk_id'))
        batch_op.drop_index(batch_op.f('ix_users_firebase_uid'))

    op.drop_table('users')
    # ### end Alembic commands ###

================
File: models/__init__.py
================
from extensions import db
from sqlalchemy.dialects.postgresql import UUID
import uuid
from datetime import datetime

class User(db.Model):
    __tablename__ = 'users'
    
    id = db.Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    firebase_uid = db.Column(db.String(128), unique=True, nullable=False, index=True)
    email = db.Column(db.String(255), nullable=False)
    kiosk_id = db.Column(db.String(8), unique=True, nullable=True, index=True) 
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    # Relationships
    wallet = db.relationship('Wallet', backref='user', uselist=False, cascade='all, delete-orphan')
    transactions = db.relationship('Transaction', backref='user', cascade='all, delete-orphan')
    withdrawals = db.relationship('Withdrawal', backref='user', cascade='all, delete-orphan')

class Wallet(db.Model):
    __tablename__ = 'wallets'
    
    id = db.Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    user_id = db.Column(UUID(as_uuid=True), db.ForeignKey('users.id'), nullable=False, unique=True)
    balance_cents = db.Column(db.Integer, default=0, nullable=False)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    def to_dict(self):
        return {
            'id': str(self.id),
            'balance_cents': self.balance_cents,
            'balance_dollars': self.balance_cents / 100,
            'updated_at': self.updated_at.isoformat()
        }

class Transaction(db.Model):
    __tablename__ = 'transactions'
    
    id = db.Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    user_id = db.Column(UUID(as_uuid=True), db.ForeignKey('users.id'), nullable=False)
    wallet_id = db.Column(UUID(as_uuid=True), db.ForeignKey('wallets.id'), nullable=False)
    transaction_type = db.Column(db.String(20), nullable=False)  # 'deposit'
    material = db.Column(db.String(50), nullable=True)  # 'plastic', 'aluminum'
    units = db.Column(db.Integer, nullable=True)
    amount_cents = db.Column(db.Integer, nullable=False)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    
    def to_dict(self):
        return {
            'id': str(self.id),
            'transaction_type': self.transaction_type,
            'material': self.material,
            'units': self.units,
            'amount_cents': self.amount_cents,
            'amount_dollars': self.amount_cents / 100,
            'created_at': self.created_at.isoformat()
        }

class Withdrawal(db.Model):
    __tablename__ = 'withdrawals'
    
    id = db.Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    user_id = db.Column(UUID(as_uuid=True), db.ForeignKey('users.id'), nullable=False)
    wallet_id = db.Column(UUID(as_uuid=True), db.ForeignKey('wallets.id'), nullable=False)
    amount_cents = db.Column(db.Integer, nullable=False)
    bank_token = db.Column(db.String(255), nullable=False)
    stripe_payment_intent_id = db.Column(db.String(255), nullable=True)
    status = db.Column(db.String(20), default='pending')  # 'pending', 'completed', 'failed'
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    processed_at = db.Column(db.DateTime, nullable=True)
    
    def to_dict(self):
        return {
            'id': str(self.id),
            'amount_cents': self.amount_cents,
            'amount_dollars': self.amount_cents / 100,
            'status': self.status,
            'created_at': self.created_at.isoformat(),
            'processed_at': self.processed_at.isoformat() if self.processed_at else None
        }

================
File: README.md
================
README
Recycling Wallet Flask API
A minimal but scalable Flask 3.0 API for a recycling wallet simulator that rewards users for depositing recyclable materials.
Features

Stateless Flask pods ready for horizontal scaling
Firebase Google Auth with server-side ID token verification
PostgreSQL with SQLAlchemy models (User, Wallet, Transaction, Withdrawal)
Rate limiting with Redis support (5 deposits per second per wallet)
Stripe integration for withdrawals (test mode/stubbed)
Five core endpoints for wallet management

Prerequisites

Python 3.12
Docker and Docker Compose
PostgreSQL client (psql)
Firebase project with Google Auth enabled
Stripe test account (optional)

Local Development Setup

Create virtual environment:
bashpython -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

Install dependencies:
bashpip install -r requirements.txt

Configure environment:
bashcp .env.example .env
# Edit .env with your values:
# - DATABASE_URL
# - FIREBASE_PROJECT_ID
# - STRIPE_SECRET_KEY (optional)

Initialize database:
bashflask db init
flask db migrate -m "Initial migration"
flask db upgrade

Run the application:
bashflask run --port 8000


The API will be available at http://localhost:8000
Docker Compose Usage
For a complete development environment with PostgreSQL and Redis:
bashdocker compose up --build
This starts:

Flask app on port 8000
PostgreSQL on port 5432
Redis on port 6379

API Endpoints
Authentication
All endpoints except /health require Firebase ID token authentication via the Authorization: Bearer <token> header.
For development/testing, you can use the bypass header:
X-Test-User-Email: test@example.com
Endpoints

GET /wallet - Get current wallet balance
POST /deposit - Deposit recyclable materials
GET /transactions?limit=50 - Get transaction history
POST /withdraw - Withdraw money to bank account
GET /withdrawals?limit=20 - Get withdrawal history
GET /health - Health check endpoint

Firebase ID Token for Testing
To get a Firebase ID token for testing:

Visit the Firebase Auth REST API documentation
Use the signInWithPassword endpoint with your test user credentials
Extract the idToken from the response
Use it in the Authorization header: Bearer <idToken>

Alternatively, use the development bypass header for quick testing:
bashcurl -H "X-Test-User-Email: test@example.com" http://localhost:8000/wallet
Postman Testing Examples
1. Get Wallet Balance
GET http://localhost:8000/wallet
Headers:
  Authorization: Bearer <firebase_id_token>
  # OR for development:
  X-Test-User-Email: test@example.com
Expected Response:
json{
  "id": "uuid-here",
  "balance_cents": 1250,
  "balance_dollars": 12.50,
  "updated_at": "2024-01-15T10:30:00.000Z"
}
2. Create Deposit
POST http://localhost:8000/deposit
Headers:
  Authorization: Bearer <firebase_id_token>
  Content-Type: application/json
Body:
{
  "material": "plastic",
  "units": 10
}
Expected Response:
json{
  "success": true,
  "transaction": {
    "id": "uuid-here",
    "transaction_type": "deposit",
    "material": "plastic",
    "units": 10,
    "amount_cents": 50,
    "amount_dollars": 0.50,
    "created_at": "2024-01-15T10:30:00.000Z"
  },
  "new_balance_cents": 1300,
  "new_balance_dollars": 13.00
}
3. Create Withdrawal
POST http://localhost:8000/withdraw
Headers:
  Authorization: Bearer <firebase_id_token>
  Content-Type: application/json
Body:
{
  "amount_cents": 1000,
  "bank_token": "tok_test_bank_account"
}
Material Rates

Plastic: 5 cents per unit
Aluminum: 10 cents per unit

Database Operations
Check wallet balance:
sqlSELECT u.email, w.balance_cents, w.balance_cents/100.0 as balance_dollars
FROM users u
JOIN wallets w ON u.id = w.user_id;
View recent transactions:
sqlSELECT u.email, t.transaction_type, t.material, t.units, t.amount_cents, t.created_at
FROM users u
JOIN transactions t ON u.id = t.user_id
ORDER BY t.created_at DESC
LIMIT 10;
View withdrawals:
sqlSELECT u.email, w.amount_cents, w.status, w.created_at
FROM users u
JOIN withdrawals w ON u.id = w.user_id
ORDER BY w.created_at DESC;
Rate Limiting
The API implements rate limiting:

5 deposits per second per wallet (configurable)
Uses Redis for distributed rate limiting
Falls back to in-memory if Redis unavailable

Production Considerations
Database Scaling
For read-heavy workloads, consider promoting a PostgreSQL replica:

Create read replica:
bash# AWS RDS example
aws rds create-db-instance-read-replica \
  --db-instance-identifier recycling-wallet-replica \
  --source-db-instance-identifier recycling-wallet-primary

Configure read-only queries:
python# In models/__init__.py, add read replica support
SQLALCHEMY_BINDS = {
    'replica': 'postgresql://user:pass@replica-host:5432/recycling_wallet'
}

# Use bind_key for read operations
transactions = Transaction.query.options(db.load_only('id', 'amount_cents'))\
    .execution_options(bind=db.get_engine(bind='replica'))\
    .filter_by(user_id=user_id).all()


Auto-scaling with Load Balancer
For horizontal pod scaling behind an Application Load Balancer:

Kubernetes Horizontal Pod Autoscaler:
yamlapiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: recycling-wallet-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: recycling-wallet
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80

Application Load Balancer configuration:
yaml# ALB ingress for AWS
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: recycling-wallet-ingress
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/healthcheck-path: /health
spec:
  rules:
  - host: api.recyclingwallet.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: recycling-wallet-service
            port:
              number: 8000

Service configuration:
yamlapiVersion: v1
kind: Service
metadata:
  name: recycling-wallet-service
spec:
  type: NodePort
  ports:
  - port: 8000
    targetPort: 8000
    protocol: TCP
  selector:
    app: recycling-wallet


Performance Monitoring
Add these environment variables for production monitoring:
env# APM and monitoring
NEW_RELIC_LICENSE_KEY=your_license_key
SENTRY_DSN=your_sentry_dsn
LOG_LEVEL=INFO

# Database connection pooling
SQLALCHEMY_ENGINE_OPTIONS='{"pool_size": 20, "max_overflow": 30, "pool_pre_ping": true}'
Security Considerations

Environment variables: Never commit real API keys to version control
HTTPS only: Use SSL termination at the load balancer level
Rate limiting: Configure Redis with proper authentication
Database security: Use connection pooling and prepared statements (handled by SQLAlchemy)
CORS: Add Flask-CORS if serving web clients from different domains

Deployment Checklist

 Set FLASK_ENV=production
 Configure proper logging levels
 Set up database backups
 Configure Redis persistence
 Set up monitoring and alerting
 Test rate limiting with load testing
 Verify Firebase token validation in production
 Test Stripe webhook endpoints (if implemented)
 Set up SSL certificates
 Configure auto-scaling policies

================
File: requirements.txt
================
Flask==3.0.0
Flask-CORS==3.0.10
Flask-SQLAlchemy==3.1.1
Flask-Migrate==4.0.5
Flask-Limiter==3.5.0
Flask-RESTX==1.3.0
psycopg2-binary==2.9.9
PyJWT==2.8.0
requests==2.31.0
python-dotenv==1.0.0
stripe==9.4.0
redis==5.0.1
gunicorn==21.2.0
gevent==23.9.1
firebase-admin==6.5.0

================
File: routes/deposit.py
================
from flask import Blueprint, request, jsonify, g
from auth.firebase import firebase_required, kiosk_only
from models import User, Wallet, Transaction
from extensions import db, limiter

deposit_bp = Blueprint("deposit", __name__)

MATERIAL_RATES = {"plastic": 5, "aluminum": 10}

@deposit_bp.route("/deposit", methods=["POST"])
@firebase_required
@limiter.limit("5 per second", key_func=lambda: f"deposit:{g.current_user.id}")
def create_deposit(current_user):
    """Create a deposit transaction - supports Firebase auth, test bypass, and kiosk ID"""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'JSON body required'}), 400
    
    material = data.get('material')
    units = data.get('units')
    
    # Validation
    if not material or material not in MATERIAL_RATES:
        return jsonify({'error': 'Invalid material. Must be "plastic" or "aluminum"'}), 400
    
    if not isinstance(units, int) or units <= 0:
        return jsonify({'error': 'Units must be a positive integer'}), 400
    
    if units > 1000:
        return jsonify({'error': 'Maximum 1000 units per deposit'}), 400
    
    # Calculate amount
    amount_cents = units * MATERIAL_RATES[material]
    
    # Get or create wallet
    wallet = Wallet.query.filter_by(user_id=current_user.id).first()
    if not wallet:
        wallet = Wallet(user_id=current_user.id)
        db.session.add(wallet)
        db.session.flush()  # Get the wallet ID
    
    # Create transaction
    transaction = Transaction(
        user_id=current_user.id,
        wallet_id=wallet.id,
        transaction_type='deposit',
        material=material,
        units=units,
        amount_cents=amount_cents
    )
    db.session.add(transaction)
    
    # Update wallet balance
    wallet.balance_cents += amount_cents
    
    try:
        db.session.commit()
        return jsonify({
            'success': True,
            'transaction': transaction.to_dict(),
            'new_balance_cents': wallet.balance_cents,
            'new_balance_dollars': wallet.balance_cents / 100,
            'user_info': {
                'email': current_user.email,
                'kiosk_id': current_user.kiosk_id
            }
        }), 201
    except Exception as e:
        db.session.rollback()
        return jsonify({'error': 'Database error occurred'}), 500

@deposit_bp.route("/deposit/kiosk", methods=["POST"])
@kiosk_only
@limiter.limit("10 per second", key_func=lambda: f"kiosk_deposit:{g.current_user.id}")
def create_kiosk_deposit(current_user):
    """Create a deposit transaction - kiosk-only endpoint that only accepts kiosk ID"""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'JSON body required'}), 400
    
    material = data.get('material')
    units = data.get('units')
    
    # Validation
    if not material or material not in MATERIAL_RATES:
        return jsonify({'error': 'Invalid material. Must be "plastic" or "aluminum"'}), 400
    
    if not isinstance(units, int) or units <= 0:
        return jsonify({'error': 'Units must be a positive integer'}), 400
    
    if units > 1000:
        return jsonify({'error': 'Maximum 1000 units per deposit'}), 400
    
    # Calculate amount
    amount_cents = units * MATERIAL_RATES[material]
    
    # Get or create wallet
    wallet = Wallet.query.filter_by(user_id=current_user.id).first()
    if not wallet:
        wallet = Wallet(user_id=current_user.id)
        db.session.add(wallet)
        db.session.flush()
    
    # Create transaction with kiosk flag
    transaction = Transaction(
        user_id=current_user.id,
        wallet_id=wallet.id,
        transaction_type='deposit',
        material=material,
        units=units,
        amount_cents=amount_cents
    )
    db.session.add(transaction)
    
    # Update wallet balance
    wallet.balance_cents += amount_cents
    
    try:
        db.session.commit()
        return jsonify({
            'success': True,
            'message': f'Deposit successful! ${amount_cents/100:.2f} added to account.',
            'transaction': transaction.to_dict(),
            'new_balance_cents': wallet.balance_cents,
            'new_balance_dollars': wallet.balance_cents / 100,
            'user_email': current_user.email
        }), 201
    except Exception as e:
        db.session.rollback()
        return jsonify({'error': 'Database error occurred'}), 500

@deposit_bp.route("/user/kiosk-id", methods=["GET"])
@firebase_required
def get_user_kiosk_id(current_user):
    """Get the current user's kiosk ID"""
    return jsonify({
        'kiosk_id': current_user.kiosk_id,
        'email': current_user.email,
        'user_id': current_user.id
    }), 200
    
@deposit_bp.route("/validate-kiosk-id", methods=["POST"])
def validate_kiosk_id():
    """Validate if a kiosk ID exists - public endpoint for kiosk validation"""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'JSON body required'}), 400
    
    kiosk_id = data.get('kiosk_id')
    
    if not kiosk_id:
        return jsonify({'error': 'kiosk_id is required'}), 400
    
    if len(kiosk_id) != 8:
        return jsonify({'error': 'kiosk_id must be 8 characters'}), 400
    
    # Check if user exists with this kiosk ID
    user = User.query.filter_by(kiosk_id=kiosk_id.upper()).first()
    
    if not user:
        return jsonify({'error': 'Invalid kiosk ID'}), 404
    
    return jsonify({
        'valid': True,
        'user_email': user.email,
        'message': f'Kiosk ID validated for {user.email}'
    }), 200
    """Validate if a kiosk ID exists - public endpoint for kiosk validation"""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'JSON body required'}), 400
    
    kiosk_id = data.get('kiosk_id')
    
    if not kiosk_id:
        return jsonify({'error': 'kiosk_id is required'}), 400
    
    if len(kiosk_id) != 8:
        return jsonify({'error': 'kiosk_id must be 8 characters'}), 400
    
    # Check if user exists with this kiosk ID
    user = User.query.filter_by(kiosk_id=kiosk_id.upper()).first()
    
    if not user:
        return jsonify({'error': 'Invalid kiosk ID'}), 404
    
    return jsonify({
        'valid': True,
        'user_email': user.email,
        'message': f'Kiosk ID validated for {user.email}'
    }), 200

================
File: routes/user.py
================
# routes/user.py
from flask import Blueprint, jsonify
from auth.firebase import firebase_required

user_bp = Blueprint("user", __name__)

@user_bp.route("/user/kiosk-id")
@firebase_required
def my_kiosk_id(current_user):
    return jsonify(kiosk_id=current_user.kiosk_id or "")

================
File: routes/wallet.py
================
from flask import Blueprint, jsonify
from auth.firebase import firebase_required
from models import Wallet
from extensions import db

wallet_bp = Blueprint('wallet', __name__)

@wallet_bp.route('/wallet', methods=['GET'])
@firebase_required
def get_wallet(current_user):
    """Get current user's wallet balance"""
    wallet = Wallet.query.filter_by(user_id=current_user.id).first()
    
    if not wallet:
        # Create wallet if it doesn't exist
        wallet = Wallet(user_id=current_user.id)
        db.session.add(wallet)
        db.session.commit()
    
    return jsonify(wallet.to_dict()), 200

@wallet_bp.route('/transactions', methods=['GET'])
@firebase_required
def get_transactions(current_user):
    """Get user's transaction history"""
    from flask import request
    from models import Transaction
    
    limit = min(int(request.args.get('limit', 50)), 100)
    
    transactions = Transaction.query.filter_by(user_id=current_user.id)\
        .order_by(Transaction.created_at.desc())\
        .limit(limit)\
        .all()
    
    return jsonify({
        'transactions': [t.to_dict() for t in transactions],
        'count': len(transactions)
    }), 200

@wallet_bp.route('/withdrawals', methods=['GET'])
@firebase_required
def get_withdrawals(current_user):
    """Get user's withdrawal history"""
    from flask import request
    from models import Withdrawal
    
    limit = min(int(request.args.get('limit', 20)), 50)
    
    withdrawals = Withdrawal.query.filter_by(user_id=current_user.id)\
        .order_by(Withdrawal.created_at.desc())\
        .limit(limit)\
        .all()
    
    return jsonify({
        'withdrawals': [w.to_dict() for w in withdrawals],
        'count': len(withdrawals)
    }), 200

================
File: routes/withdraw.py
================
# routes/withdraw.py
from flask import Blueprint, request, jsonify, current_app
from auth.firebase import firebase_required
from models import Wallet, Withdrawal
from extensions import db
import stripe, os
from datetime import datetime

withdraw_bp = Blueprint("withdraw", __name__)
stripe.api_key = os.getenv("STRIPE_SECRET_KEY")

@withdraw_bp.route("/withdraw", methods=["POST"])
@firebase_required
def create_withdrawal(current_user):
    data = request.get_json(silent=True) or {}
    amount_cents = data.get("amount_cents")
    bank_token   = data.get("bank_token")

    # validation (unchanged) ...
    if not isinstance(amount_cents, int) or amount_cents <= 0:
        return jsonify(error="Amount must be a positive integer in cents"), 400
    if amount_cents < 100:
        return jsonify(error="Minimum withdrawal is $1.00"), 400
    if not bank_token or not isinstance(bank_token, str):
        return jsonify(error="Bank token required"), 400

    wallet = Wallet.query.filter_by(user_id=current_user.id).first()
    if not wallet:
        return jsonify(error="Wallet not found"), 404
    if wallet.balance_cents < amount_cents:
        return jsonify(error="Insufficient balance"), 400

    withdrawal = Withdrawal(
        user_id=current_user.id,
        wallet_id=wallet.id,
        amount_cents=amount_cents,
        bank_token=bank_token,
        status="pending",
    )
    db.session.add(withdrawal)
    wallet.balance_cents -= amount_cents
    db.session.commit()            # withdrawal.id now exists

    # ───────────────── Stripe Payout ─────────────────
    try:
        if stripe.api_key and stripe.api_key.startswith("sk_"):
            payout = stripe.Payout.create(
                amount      = amount_cents,
                currency    = "usd",
                method      = "standard",          # or "instant"
                statement_descriptor = "RECYCLETEK",
                idempotency_key      = f"wd-{withdrawal.id}",
            )

            withdrawal.status = "completed"
            
            # Only set these fields if they exist in your model
            if hasattr(withdrawal, 'processed_at'):
                withdrawal.processed_at = datetime.utcnow()
            if hasattr(withdrawal, 'stripe_reference_id'):
                withdrawal.stripe_reference_id = payout.id
            
            db.session.commit()

        else:  # stub mode
            withdrawal.status = "completed"
            
            if hasattr(withdrawal, 'processed_at'):
                withdrawal.processed_at = datetime.utcnow()
            if hasattr(withdrawal, 'stripe_reference_id'):
                withdrawal.stripe_reference_id = f"stub_payout_{withdrawal.id}"
            
            db.session.commit()

    except stripe.error.StripeError as se:
        wallet.balance_cents += amount_cents   # undo debit
        withdrawal.status = "failed"
        db.session.commit()
        current_app.logger.error(f"Stripe payout error: {se}")
        return jsonify(error="Payout failed"), 500
    except Exception as e:
        # Catch any other errors (like database/attribute errors)
        wallet.balance_cents += amount_cents   # undo debit
        withdrawal.status = "failed"
        db.session.commit()
        current_app.logger.error(f"Withdrawal processing error: {e}")
        return jsonify(error="Withdrawal processing failed"), 500

    # Safe response construction
    try:
        response_data = {
            "success": True,
            "withdrawal": {
                "id": withdrawal.id,
                "user_id": withdrawal.user_id,
                "amount_cents": withdrawal.amount_cents,
                "status": withdrawal.status,
                "created_at": withdrawal.created_at.isoformat() if hasattr(withdrawal, 'created_at') else None,
            },
            "new_balance_cents": wallet.balance_cents,
            "new_balance_dollars": wallet.balance_cents / 100,
        }
        
        # Add optional fields if they exist
        if hasattr(withdrawal, 'processed_at') and withdrawal.processed_at:
            response_data["withdrawal"]["processed_at"] = withdrawal.processed_at.isoformat()
        if hasattr(withdrawal, 'stripe_reference_id') and withdrawal.stripe_reference_id:
            response_data["withdrawal"]["stripe_reference_id"] = withdrawal.stripe_reference_id
        
        return jsonify(response_data), 201
        
    except Exception as e:
        current_app.logger.error(f"Response construction error: {e}")
        return jsonify(error="Response construction failed"), 500
